{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680bd6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "import sys\n",
    "import re\n",
    "import calendar\n",
    "\n",
    "\n",
    "# Paths\n",
    "csv_folder  = r\"D:\\TRAINING MODEL\\data\\csv_folder\"\n",
    "logs_folder = r\"D:\\TRAINING MODEL\\logs\"\n",
    "\n",
    "# File path\n",
    "log_file = os.path.join(logs_folder, \"processed_files.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95823df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final column schema\n",
    "final_columns = [\n",
    "    \"Month_year\", \"Consultation_Type\", \"Case\",\n",
    "    \"Under 1 Male\", \"Under 1 Female\",\n",
    "    \"1-4 Male\", \"1-4 Female\",\n",
    "    \"5-9 Male\", \"5-9 Female\",\n",
    "    \"10-14 Male\", \"10-14 Female\",\n",
    "    \"15-18 Male\", \"15-18 Female\",\n",
    "    \"19-24 Male\", \"19-24 Female\",\n",
    "    \"25-29 Male\", \"25-29 Female\",\n",
    "    \"30-34 Male\", \"30-34 Female\",\n",
    "    \"35-39 Male\", \"35-39 Female\",\n",
    "    \"40-44 Male\", \"40-44 Female\",\n",
    "    \"45-49 Male\", \"45-49 Female\",\n",
    "    \"50-54 Male\", \"50-54 Female\",\n",
    "    \"55-59 Male\", \"55-59 Female\",\n",
    "    \"60-64 Male\", \"60-64 Female\",\n",
    "    \"65-69 Male\", \"65-69 Female\",\n",
    "    \"70 Over Male\", \"70 Over Female\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Load already processed files\n",
    "# --------------------------\n",
    "processed_files = set()\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, \"r\") as f:\n",
    "        processed_files = set(line.strip() for line in f.readlines())\n",
    "        \n",
    "# --------------------------\n",
    "# Scan and process only NEW CSV files\n",
    "# --------------------------\n",
    "for file in os.listdir(csv_folder):\n",
    "    if file.endswith(\".csv\") and file not in processed_files:  # ✅ Skip logged files\n",
    "        file_path = os.path.join(csv_folder, file)\n",
    "        try:\n",
    "            # Read CSV\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Drop first column (extra index column)\n",
    "            df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "            # Add 2 new columns on the left\n",
    "            df.insert(0, \"Month_year\", \"\")\n",
    "            df.insert(1, \"Consultation_Type\", \"\")\n",
    "\n",
    "            # If too many columns → trim\n",
    "            if df.shape[1] > len(final_columns):\n",
    "                df = df.iloc[:, :len(final_columns)]\n",
    "\n",
    "            # If too few columns → pad with empty ones\n",
    "            while df.shape[1] < len(final_columns):\n",
    "                df[f\"Extra_{df.shape[1]}\"] = \"\"\n",
    "\n",
    "            # Rename columns\n",
    "            df.columns = final_columns\n",
    "\n",
    "            # Save cleaned CSV (overwrites original inside csv_folder)\n",
    "            df.to_csv(file_path, index=False)\n",
    "\n",
    "            # Append this file to log\n",
    "            with open(log_file, \"a\") as f:\n",
    "                f.write(file + \"\\n\")\n",
    "\n",
    "            print(f\"✅ Processed and logged: {file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {file}: {e}\")\n",
    "\n",
    "print(\"🎯 All new CSV files processed and logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload processed files\n",
    "with open(log_file, \"r\") as f:\n",
    "    processed_files = set(line.strip() for line in f.readlines())\n",
    "\n",
    "# Update Month_year in each processed file\n",
    "for file in processed_files:\n",
    "    file_path = os.path.join(csv_folder, file)\n",
    "    try:\n",
    "        # Read raw text\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # Extract month and year\n",
    "        match = re.search(r\"MONTH AND YEAR:\\s*([A-Za-z]+)\\s+(\\d{4})\", text)\n",
    "        month_year_value = \"\"\n",
    "        if match:\n",
    "            month_name = match.group(1).strip().title()\n",
    "            year = match.group(2).strip()\n",
    "            try:\n",
    "                month_num = list(calendar.month_name).index(month_name)\n",
    "                month_year_value = f\"{year} - {month_num}\"\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        # Update dataframe\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"Month_year\"] = month_year_value\n",
    "\n",
    "        # Save back\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Updated {file} with Month_year={month_year_value}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating {file}: {e}\")\n",
    "\n",
    "print(\"All Month_year values updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66691fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open log file\n",
    "with open(log_file, \"a\", encoding=\"utf-8\") as log:\n",
    "    # Loop through all CSV files\n",
    "    for file in os.listdir(csv_folder):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(csv_folder, file)\n",
    "\n",
    "            print(f\"\\n📂 Processing: {file}\")\n",
    "\n",
    "            # Load CSV\n",
    "            final_df = pd.read_csv(file_path)\n",
    "\n",
    "            # Keep a mapping and current category\n",
    "            current_category = None\n",
    "            found_categories = []\n",
    "\n",
    "            # Create a new column for Consultation_Type if not present\n",
    "            if \"Consultation_Type\" not in final_df.columns:\n",
    "                final_df.insert(1, \"Consultation_Type\", \"\")\n",
    "\n",
    "            # Iterate row by row\n",
    "            for i, row in final_df.iterrows():\n",
    "                for cell in row.dropna().astype(str):\n",
    "                    if \"TOP 10\" in cell.upper():\n",
    "                        # Extract last word (category)\n",
    "                        last_word = re.sub(r\"[^\\w]\", \"\", cell.strip().split()[-1])\n",
    "                        current_category = last_word.capitalize()\n",
    "                        found_categories.append((i, current_category))\n",
    "                        print(f\"✅ Found: {current_category} at row {i}\")\n",
    "                        break  # stop after first match in this row\n",
    "\n",
    "                # Fill Consultation_Type with current_category\n",
    "                if current_category:\n",
    "                    final_df.at[i, \"Consultation_Type\"] = current_category\n",
    "\n",
    "            # Save updated file (overwrite original in csv_folder)\n",
    "            final_df.to_csv(file_path, index=False)\n",
    "\n",
    "\n",
    "            print(f\"💾 Saved updated file: {file}\")\n",
    "            print(\"🔍 Unique categories found:\", set(cat for _, cat in found_categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all CSV files in folder\n",
    "\n",
    "drop_indexes = []\n",
    "\n",
    "for file in os.listdir(csv_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(csv_folder, file)\n",
    "        print(f\"\\n📂 Cleaning file: {file}\")\n",
    "\n",
    "        # Load CSV\n",
    "        final_df = pd.read_csv(file_path)\n",
    "\n",
    "        # Find rows to drop\n",
    "        drop_indexes = []\n",
    "        for i, row in final_df.iterrows():\n",
    "            for cell in row.dropna().astype(str):\n",
    "                if \"PASIG CITY CHILDREN'S HOSPITAL/PASIG CITY COVID-19 REFERRAL CENTER\" in cell.upper():\n",
    "                    drop_indexes.extend(range(i, i + 9))  # this row + 8    below\n",
    "                    break\n",
    "\n",
    "        # Find rows containing \"TOTAL\"\n",
    "        for i, row in final_df.iterrows():\n",
    "            for cell in row.dropna().astype(str):\n",
    "                if \"TOTAL\" in cell.upper().strip():\n",
    "                    # Add this row and the next 2 rows\n",
    "                    drop_indexes.extend([i, i+1, i+2])\n",
    "                    break  # stop checking other cells in the same row\n",
    "\n",
    "        # Drop duplicates in case overlaps happen\n",
    "        drop_indexes = list(set(drop_indexes))\n",
    "\n",
    "        # Drop rows and reset index\n",
    "        final_df = final_df.drop(drop_indexes, errors=\"ignore\").reset_index(drop=True)\n",
    "\n",
    "        # Save back to CSV\n",
    "        final_df.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"✅ Removed {len(drop_indexes)} rows and updated file: {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
