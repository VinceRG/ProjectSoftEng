{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e6415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Adding: TOP 10 LEADING APRIL 2023.csv\n",
      "üìÇ Adding: TOP 10 LEADING AUGUST 2023.csv\n",
      "üìÇ Adding: TOP 10 LEADING DECEMBER 2023.csv\n",
      "üìÇ Adding: TOP 10 LEADING JULY 2023.csv\n",
      "üìÇ Adding: TOP 10 LEADING JUNE 2023.csv\n",
      "üìÇ Adding: TOP 10 LEADING NOVEMBER 2023.csv\n",
      "üìÇ Adding: TOP 10 LEADING OCTOBER 2023.csv\n",
      "üìÇ Adding: TOP 10 LEADING SEPTEMBER 2023.csv\n",
      "‚úÖ Updated D:\\TRAINING MODEL\\data\\processed\\master_dataset.csv with 8 new files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Paths\n",
    "csv_folder  = r\"D:\\TRAINING MODEL\\data\\csv_folder\"\n",
    "logs_folder = r\"D:\\TRAINING MODEL\\logs\"\n",
    "out_folder  = r\"D:\\TRAINING MODEL\\data\\processed\"\n",
    "\n",
    "# Master CSV and log file\n",
    "master_csv = os.path.join(out_folder, \"master_dataset.csv\")\n",
    "log_file   = os.path.join(logs_folder, \"csv_master_log.txt\")\n",
    "\n",
    "# Ensure folders exist\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(logs_folder, exist_ok=True)\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "# Load processed file log\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, \"r\") as f:\n",
    "        processed_files = set(line.strip() for line in f)\n",
    "else:\n",
    "    processed_files = set()\n",
    "\n",
    "# Find all CSV files\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.lower().endswith(\".csv\")]\n",
    "\n",
    "new_dataframes = []\n",
    "new_files = []\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(csv_folder, file)\n",
    "    \n",
    "    if file not in processed_files:  # Only new files\n",
    "        print(f\"üìÇ Adding: {file}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        new_dataframes.append(df)\n",
    "        new_files.append(file)\n",
    "\n",
    "if new_dataframes:\n",
    "    combined_df = pd.concat(new_dataframes, ignore_index=True)\n",
    "\n",
    "    # If master CSV exists, append without header\n",
    "    if os.path.exists(master_csv):\n",
    "        combined_df.to_csv(master_csv, mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        combined_df.to_csv(master_csv, mode=\"w\", header=True, index=False)\n",
    "\n",
    "    # Update log file\n",
    "    with open(log_file, \"a\") as f:\n",
    "        for file in new_files:\n",
    "            f.write(file + \"\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Updated {master_csv} with {len(new_files)} new files\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No new files to add.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af4644c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned master CSV, remaining rows: 241\n"
     ]
    }
   ],
   "source": [
    "# Load the master CSV\n",
    "df = pd.read_csv(master_csv)\n",
    "\n",
    "# Remove rows where 'Case' is empty (NaN or blank)\n",
    "df = df[df[\"Case\"].notna()]            # drop NaN\n",
    "df = df[df[\"Case\"].astype(str).str.strip() != \"\"]  # drop empty strings\n",
    "\n",
    "# Save cleaned dataset back\n",
    "df.to_csv(master_csv, index=False)\n",
    "\n",
    "print(f\"‚úÖ Cleaned master CSV, remaining rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b54f36f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Case dictionary updated. Total cases: 108\n"
     ]
    }
   ],
   "source": [
    "# Path to dictionary file\n",
    "case_dict_file = os.path.join(logs_folder, \"case_dictionary.json\")\n",
    "\n",
    "# Load existing dictionary if it exists\n",
    "if os.path.exists(case_dict_file):\n",
    "    with open(case_dict_file, \"r\") as f:\n",
    "        case_dict = json.load(f)\n",
    "else:\n",
    "    case_dict = {}\n",
    "\n",
    "# Load the master CSV\n",
    "df = pd.read_csv(master_csv)\n",
    "\n",
    "# Get all unique Case values\n",
    "unique_cases = df[\"Case\"].dropna().astype(str).str.strip().unique()\n",
    "\n",
    "# Update dictionary with new cases\n",
    "for case in unique_cases:\n",
    "    if case not in case_dict:\n",
    "        case_dict[case] = len(case_dict) + 1   # assign next ID (or any scheme you like)\n",
    "\n",
    "# Save dictionary back to file\n",
    "with open(case_dict_file, \"w\") as f:\n",
    "    json.dump(case_dict, f, indent=4)\n",
    "\n",
    "print(f\"‚úÖ Case dictionary updated. Total cases: {len(case_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9389c65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Converted 'Case' column into numeric codes using case dictionary\n"
     ]
    }
   ],
   "source": [
    "# Load case dictionary\n",
    "with open(case_dict_file, \"r\") as f:\n",
    "    case_dict = json.load(f)\n",
    "\n",
    "# Load master CSV\n",
    "df = pd.read_csv(master_csv)\n",
    "\n",
    "# Map Case column to numbers using dictionary\n",
    "df[\"Case\"] = df[\"Case\"].astype(str).str.strip().map(case_dict)\n",
    "\n",
    "# Save updated dataset\n",
    "df.to_csv(master_csv, index=False)\n",
    "\n",
    "print(\"‚úÖ Converted 'Case' column into numeric codes using case dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08ef3552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Converted 'Consultation_Type' column into numeric codes\n"
     ]
    }
   ],
   "source": [
    "# Load master CSV\n",
    "df = pd.read_csv(master_csv)\n",
    "\n",
    "# Define mapping for Consultation_Type\n",
    "consultation_map = {\n",
    "    \"Consultation\": 1,\n",
    "    \"Diagnosis\": 2,\n",
    "    \"Mortality\": 3\n",
    "}\n",
    "\n",
    "# Apply mapping (ignores NaN and unexpected values)\n",
    "df[\"Consultation_Type\"] = df[\"Consultation_Type\"].map(consultation_map)\n",
    "\n",
    "# Save back to master CSV\n",
    "df.to_csv(master_csv, index=False)\n",
    "\n",
    "print(\"‚úÖ Converted 'Consultation_Type' column into numeric codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fab8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cae4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
