{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791114b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ New files found: ['TOP 10 LEADING APRIL 2023.csv', 'TOP 10 LEADING APRIL 2024.csv', 'TOP 10 LEADING AUGUST 2023.csv', 'TOP 10 LEADING AUGUST 2024.csv', 'TOP 10 LEADING DEC 2024.csv', 'TOP 10 LEADING DECEMBER 2023.csv', 'TOP 10 LEADING FEB 2024.csv', 'TOP 10 LEADING JAN 2024.csv', 'TOP 10 LEADING JULY 2023.csv', 'TOP 10 LEADING JULY 2024.csv', 'TOP 10 LEADING JUNE 2023.csv', 'TOP 10 LEADING JUNE 2024.csv', 'TOP 10 LEADING MARCH 2024.csv', 'TOP 10 LEADING MAY 2023.csv', 'TOP 10 LEADING MAY 2024 (1).csv', 'TOP 10 LEADING NOV 2024.csv', 'TOP 10 LEADING NOVEMBER 2023.csv', 'TOP 10 LEADING OCTOBER 2023.csv', 'TOP 10 LEADING OCTOBER 2024 .csv', 'TOP 10 LEADING SEPTEMBER 2023.csv', 'TOP 10 LEADING SEPTEMBER 2024.csv']\n",
      "‚úÖ Appended 21 files to master\n",
      "üìä Total rows in master: 626\n",
      "üìñ Case dictionary size: 191\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ----------------------------\n",
    "# Paths\n",
    "# ----------------------------\n",
    "csv_folder  = r\"D:\\TRAINING MODEL\\data\\csv_folder\"\n",
    "logs_folder = r\"D:\\TRAINING MODEL\\logs\"\n",
    "out_folder  = r\"D:\\TRAINING MODEL\\data\\processed\"\n",
    "\n",
    "master_csv      = os.path.join(out_folder, \"master_dataset.csv\")\n",
    "log_file        = os.path.join(logs_folder, \"csv_master_log.txt\")\n",
    "case_dict_file  = os.path.join(logs_folder, \"case_dictionary.json\")\n",
    "\n",
    "# ----------------------------\n",
    "# Ensure folders exist\n",
    "# ----------------------------\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(logs_folder, exist_ok=True)\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Load processed file log\n",
    "# ----------------------------\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, \"r\") as f:\n",
    "        processed_files = set(line.strip() for line in f)\n",
    "else:\n",
    "    processed_files = set()\n",
    "\n",
    "# ----------------------------\n",
    "# Scan for new CSV files\n",
    "# ----------------------------\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.lower().endswith(\".csv\")]\n",
    "new_files = [f for f in csv_files if f not in processed_files]\n",
    "\n",
    "if not new_files:\n",
    "    print(\"‚ö†Ô∏è No new files to process.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"üìÇ New files found: {new_files}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Load or create case dictionary\n",
    "# ----------------------------\n",
    "if os.path.exists(case_dict_file):\n",
    "    with open(case_dict_file, \"r\") as f:\n",
    "        case_dict = json.load(f)\n",
    "else:\n",
    "    case_dict = {}\n",
    "\n",
    "# ----------------------------\n",
    "# Consultation mapping\n",
    "# ----------------------------\n",
    "consultation_map = {\n",
    "    \"Consultation\": 1,\n",
    "    \"Diagnosis\": 2,\n",
    "    \"Mortality\": 3\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Function to safely load CSV\n",
    "# ----------------------------\n",
    "def safe_load_csv(file_path):\n",
    "    return pd.read_csv(file_path, engine=\"python\", on_bad_lines=\"skip\")\n",
    "\n",
    "# ----------------------------\n",
    "# Process new files\n",
    "# ----------------------------\n",
    "processed_dfs = []\n",
    "\n",
    "for file in new_files:\n",
    "    file_path = os.path.join(csv_folder, file)\n",
    "    df = safe_load_csv(file_path)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è Skipping {file}: no valid rows\")\n",
    "        continue\n",
    "\n",
    "    # Align columns with master if exists\n",
    "    if os.path.exists(master_csv):\n",
    "        old_master = safe_load_csv(master_csv)\n",
    "        master_columns = old_master.columns\n",
    "        for col in master_columns:\n",
    "            if col not in df.columns:\n",
    "                df[col] = None\n",
    "        df = df.reindex(columns=master_columns)\n",
    "\n",
    "    # Clean 'Case' column\n",
    "    if \"Case\" not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è Skipping {file}: no 'Case' column found\")\n",
    "        continue\n",
    "\n",
    "    df = df[df[\"Case\"].notna()]\n",
    "    df[\"Case\"] = df[\"Case\"].astype(str).str.strip()\n",
    "    df = df[df[\"Case\"] != \"\"]\n",
    "\n",
    "    # Update case dictionary\n",
    "    unique_cases = df[\"Case\"].unique()\n",
    "    for case in unique_cases:\n",
    "        if case not in case_dict:\n",
    "            case_dict[case] = len(case_dict) + 1\n",
    "\n",
    "    df[\"Case\"] = df[\"Case\"].map(case_dict)\n",
    "\n",
    "    # Encode Consultation_Type\n",
    "    if \"Consultation_Type\" in df.columns:\n",
    "        df[\"Consultation_Type\"] = df[\"Consultation_Type\"].map(consultation_map)\n",
    "\n",
    "    processed_dfs.append(df)\n",
    "\n",
    "# ----------------------------\n",
    "# Append to master\n",
    "# ----------------------------\n",
    "if processed_dfs:\n",
    "    new_data = pd.concat(processed_dfs, ignore_index=True)\n",
    "\n",
    "    if os.path.exists(master_csv):\n",
    "        old_master = safe_load_csv(master_csv)\n",
    "        combined_df = pd.concat([old_master, new_data], ignore_index=True)\n",
    "    else:\n",
    "        combined_df = new_data\n",
    "\n",
    "    combined_df.to_csv(master_csv, index=False)\n",
    "\n",
    "    # Save case dictionary\n",
    "    with open(case_dict_file, \"w\") as f:\n",
    "        json.dump(case_dict, f, indent=4)\n",
    "\n",
    "    # Update log\n",
    "    with open(log_file, \"a\") as f:\n",
    "        for file in new_files:\n",
    "            f.write(file + \"\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Appended {len(new_files)} files to master\")\n",
    "    print(f\"üìä Total rows in master: {len(combined_df)}\")\n",
    "    print(f\"üìñ Case dictionary size: {len(case_dict)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid rows to add from new files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a91d587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
