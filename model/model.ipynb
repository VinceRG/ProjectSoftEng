{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d4be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import os\n",
    "\n",
    "base_folder = r\"D:\\TRAINING MODEL\"\n",
    "out_folder  = os.path.join(base_folder, \"data\", \"processed\")\n",
    "df = pd.read_csv(os.path.join(out_folder, \"master_dataset_cleaned.csv\"))\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows where Total is NaN (since it's the target)\n",
    "df = df.dropna(subset=[\"Total\"])\n",
    "\n",
    "# Optionally, fill NaNs in features with 0 or mean\n",
    "df = df.fillna(0)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Features (X) and Target (y)\n",
    "X = df.drop(\"Total\", axis=1)\n",
    "y = df[\"Total\"]\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create and train model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Error metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"RÂ²:\", r2)\n",
    "\n",
    "# Comparison DataFrame\n",
    "comparison = pd.DataFrame({\n",
    "    \"Actual\": y_test.reset_index(drop=True),\n",
    "    \"Predicted\": y_pred\n",
    "})\n",
    "print(comparison.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cf61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import itertools\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Mappings for Readability ---\n",
    "consultation_map = {1: \"Consultation\", 2: \"Diagnosis\", 3: \"Mortality\"}\n",
    "\n",
    "# --- 1. Load Data and Case Mappings ---\n",
    "try:\n",
    "    df = pd.read_csv('master_dataset_cleaned.csv')\n",
    "    print(\"--- Data Loaded Successfully ---\")\n",
    "    print(f\"Shape of the dataset: {df.shape}\\n\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'master_dataset_cleaned.csv' not found. Please ensure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    with open('case_dictionary.json', 'r') as f:\n",
    "        # Load JSON. The file has names as keys and IDs as values.\n",
    "        case_map_str_keys = json.load(f)\n",
    "        # We need to invert the dictionary so IDs are keys and names are values.\n",
    "        case_map = {v: k for k, v in case_map_str_keys.items()}\n",
    "    print(\"--- Case Dictionary Loaded Successfully ---\\n\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'case_dictionary.json' not found. Please ensure the file is in the correct directory.\")\n",
    "    # Fallback to an empty dictionary if file not found\n",
    "    case_map = {}\n",
    "\n",
    "\n",
    "# --- 2. Data Analysis & Feature Engineering ---\n",
    "\n",
    "# GOAL: Get total of each consultation_type per year\n",
    "print(\"--- Annual Totals per Consultation Type ---\")\n",
    "annual_totals = df.groupby(['Year', 'Consultation_Type'])['Total'].sum().reset_index()\n",
    "annual_totals['Consultation_Type_Name'] = annual_totals['Consultation_Type'].map(consultation_map)\n",
    "print(annual_totals[['Year', 'Consultation_Type_Name', 'Total']])\n",
    "print(\"\\n\")\n",
    "\n",
    "# GOAL: Create outbreak flags for holidays\n",
    "print(\"--- Holiday Correlation Analysis (Outbreak Flag) ---\")\n",
    "holiday_months = [1, 11, 12] # Jan (New Year), Nov (Undas), Dec (Christmas)\n",
    "df['is_major_holiday'] = df['Month'].isin(holiday_months).astype(int)\n",
    "\n",
    "monthly_totals = df.groupby(['Year', 'Month'])['Total'].sum().reset_index()\n",
    "monthly_totals['is_major_holiday'] = monthly_totals['Month'].isin(holiday_months).astype(int)\n",
    "\n",
    "holiday_avg = monthly_totals[monthly_totals['is_major_holiday'] == 1]['Total'].mean()\n",
    "non_holiday_avg = monthly_totals[monthly_totals['is_major_holiday'] == 0]['Total'].mean()\n",
    "\n",
    "print(f\"Average total cases on major holiday months (Jan, Nov, Dec): {holiday_avg:.2f}\")\n",
    "print(f\"Average total cases on non-holiday months: {non_holiday_avg:.2f}\")\n",
    "\n",
    "# Plot the correlation/comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=['Holiday Months (Jan, Nov, Dec)', 'Non-Holiday Months'], y=[holiday_avg, non_holiday_avg], palette=['skyblue', 'lightgrey'])\n",
    "plt.title('Average Monthly Cases: Holiday vs. Non-Holiday')\n",
    "plt.ylabel('Average Total Cases')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig('holiday_correlation_chart.png')\n",
    "# print(\"Generated 'holiday_correlation_chart.png' plot.\\n\")\n",
    "\n",
    "# --- 3. Model Training and Evaluation (Using Your Script's Method) ---\n",
    "print(\"--- Building and Evaluating Random Forest Model ---\")\n",
    "# Features (X) and Target (y)\n",
    "X = df.drop(\"Total\", axis=1)\n",
    "y = df[\"Total\"]\n",
    "\n",
    "# Split dataset using a random split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "\n",
    "# Create and train model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=5)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred[y_pred < 0] = 0 # Ensure predictions are non-negative\n",
    "\n",
    "# GOAL: Use R^2 and MAE for testing\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Model Evaluation (on 20% Random Test Set) ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"R-squared (RÂ²): {r2:.4f}\\n\")\n",
    "\n",
    "# --- 4. Monthly Prediction of Top Cases ---\n",
    "print(\"--- Predicting Top Cases for Next Month ---\")\n",
    "# Find last date in the dataset\n",
    "last_year = df['Year'].max()\n",
    "last_month = df[df['Year'] == last_year]['Month'].max()\n",
    "\n",
    "# Calculate the next month\n",
    "if last_month == 12:\n",
    "    next_month = 1\n",
    "    next_year = last_year + 1\n",
    "else:\n",
    "    next_month = last_month + 1\n",
    "    next_year = last_year\n",
    "\n",
    "print(f\"Data last recorded in: {last_year}-{last_month:02d}\")\n",
    "print(f\"Predicting for: {next_year}-{next_month:02d}\")\n",
    "\n",
    "# Create a future prediction grid\n",
    "all_cases = df['Case'].unique()\n",
    "all_consult_types = df['Consultation_Type'].unique()\n",
    "all_sexes = df['Sex'].unique()\n",
    "all_age_ranges = df['Age_range'].unique()\n",
    "\n",
    "future_combinations = list(itertools.product(all_consult_types, all_cases, all_sexes, all_age_ranges))\n",
    "X_future = pd.DataFrame(future_combinations, columns=['Consultation_Type', 'Case', 'Sex', 'Age_range'])\n",
    "\n",
    "# Add other necessary features for prediction\n",
    "X_future['Year'] = next_year\n",
    "X_future['Month'] = next_month\n",
    "X_future['is_major_holiday'] = 1 if next_month in holiday_months else 0\n",
    "X_future = X_future[X_train.columns] # Ensure column order matches training data\n",
    "\n",
    "# Make predictions\n",
    "future_predictions = model.predict(X_future)\n",
    "future_predictions[future_predictions < 0] = 0\n",
    "X_future['Predicted_Total'] = future_predictions\n",
    "\n",
    "# Aggregate to find top cases\n",
    "future_case_totals = X_future.groupby(['Consultation_Type', 'Case'])['Predicted_Total'].sum().reset_index()\n",
    "future_case_totals['Predicted_Total'] = future_case_totals['Predicted_Total'].round(0).astype(int)\n",
    "\n",
    "# Get top 5 for each consultation type\n",
    "top_5_predictions = future_case_totals.sort_values('Predicted_Total', ascending=False).groupby('Consultation_Type').head(5)\n",
    "\n",
    "# Map names for readability\n",
    "top_5_predictions['Consultation_Type_Name'] = top_5_predictions['Consultation_Type'].map(consultation_map)\n",
    "top_5_predictions['Case_Name'] = top_5_predictions['Case'].map(case_map).fillna(top_5_predictions['Case'].apply(lambda x: f'Case {x} (No Name)'))\n",
    "\n",
    "print(\"\\n--- Top 5 Predicted Cases for Next Month ---\")\n",
    "print(top_5_predictions.sort_values(by=['Consultation_Type_Name', 'Predicted_Total'], ascending=[True, False])[['Consultation_Type_Name', 'Case_Name', 'Predicted_Total']])\n",
    "\n",
    "# --- 5. 2024 Actual vs. Predicted Comparison ---\n",
    "print(\"\\n--- Comparing Actual vs. Predicted Top 20 Cases for 2024 ---\")\n",
    "\n",
    "# Isolate all data from 2024\n",
    "df_2024 = df[df['Year'] == 2024].copy()\n",
    "\n",
    "# Define features and actual totals for 2024\n",
    "X_2024 = df_2024.drop('Total', axis=1)\n",
    "y_2024_actual = df_2024['Total']\n",
    "\n",
    "# Use the trained model to predict on 2024 data\n",
    "y_2024_pred = model.predict(X_2024)\n",
    "y_2024_pred[y_2024_pred < 0] = 0\n",
    "\n",
    "# Create a new DataFrame for comparison\n",
    "comparison_2024_df = X_2024.copy()\n",
    "comparison_2024_df['Actual_Total'] = y_2024_actual\n",
    "comparison_2024_df['Predicted_Total'] = y_2024_pred.round(0).astype(int)\n",
    "\n",
    "# Aggregate totals by case for a clearer view\n",
    "actual_2024_totals = comparison_2024_df.groupby('Case')['Actual_Total'].sum()\n",
    "predicted_2024_totals = comparison_2024_df.groupby('Case')['Predicted_Total'].sum()\n",
    "\n",
    "# Get the top 20 actual cases\n",
    "top_20_actual_cases = actual_2024_totals.nlargest(20).index\n",
    "\n",
    "# Combine the results for the top 20 cases\n",
    "comparison_summary = pd.DataFrame({\n",
    "    'Actual_Total': actual_2024_totals[top_20_actual_cases],\n",
    "    'Predicted_Total': predicted_2024_totals[top_20_actual_cases]\n",
    "}).reset_index()\n",
    "\n",
    "# Map case names for readability\n",
    "comparison_summary['Case_Name'] = comparison_summary['Case'].map(case_map)\n",
    "\n",
    "print(comparison_summary[['Case_Name', 'Actual_Total', 'Predicted_Total']])\n",
    "# --- Visualization: Actual vs Predicted Totals for 2024 ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "comparison_summary_sorted = comparison_summary.sort_values(by=\"Actual_Total\", ascending=False)\n",
    "\n",
    "# Plot bars for Actual vs Predicted\n",
    "bar_width = 0.35\n",
    "indices = np.arange(len(comparison_summary_sorted))\n",
    "\n",
    "plt.bar(indices, comparison_summary_sorted['Actual_Total'], bar_width, label='Actual 2024', alpha=0.7)\n",
    "plt.bar(indices + bar_width, comparison_summary_sorted['Predicted_Total'], bar_width, label='Predicted 2024', alpha=0.7)\n",
    "\n",
    "plt.xticks(indices + bar_width / 2, comparison_summary_sorted['Case_Name'], rotation=75, ha='right')\n",
    "plt.xlabel('Case Name')\n",
    "plt.ylabel('Total Cases')\n",
    "plt.title('Actual vs Predicted Total Cases (Top 20, 2024)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('actual_vs_predicted_2024.png')\n",
    "# plt.show()\n",
    "plt.show\n",
    "\n",
    "print(\"\\nGenerated 'actual_vs_predicted_2024.png' showing Actual vs Predicted totals for 2024.\")\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred[y_pred < 0] = 0  # Ensure predictions are non-negative\n",
    "\n",
    "# --- Model Evaluation ---\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Model Evaluation (on 20% Random Test Set) ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"R-squared (RÂ²): {r2:.4f}\")\n",
    "\n",
    "# Optional: Show a quick visual comparison\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(f\"Random Forest Regression (RÂ² = {r2:.4f}, MSE = {mse:.4f})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig('model_performance_scatter.png')\n",
    "# print(\"Generated 'model_performance_scatter.png' showing actual vs predicted values.\\n\")\n",
    "import joblib\n",
    "\n",
    "# --- 6. Save the Trained Model ---\n",
    "# model_filename = 'random_forest_model.pkl'\n",
    "# joblib.dump(model, model_filename)\n",
    "\n",
    "# print(f\"\\nâœ… Model saved successfully as '{model_filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab571f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading dataset ---\n",
      "Dataset shape: (20032, 7)\n",
      "\n",
      "--- Records for Year=2023, Consultation_Type=3, Case=1 (Fever) ---\n",
      "       Year  Month  Consultation_Type  Case  Sex  Age_range  Total\n",
      "0      2023      4                  1     1    1          0     29\n",
      "62     2023      8                  1     1    1          0     22\n",
      "151    2023     12                  1     1    1          0     39\n",
      "237    2023      7                  1     1    1          0     35\n",
      "297    2023      6                  1     1    1          0     47\n",
      "...     ...    ...                ...   ...  ...        ...    ...\n",
      "19703  2023      6                  1     1    0         15      2\n",
      "19793  2023      5                  1     1    0         15      1\n",
      "19885  2023     11                  1     1    0         15      2\n",
      "19911  2023     10                  1     1    0         15      0\n",
      "19971  2023      9                  1     1    0         15      1\n",
      "\n",
      "[288 rows x 7 columns]\n",
      "\n",
      "Total Records Found: 288\n",
      "\n",
      "--- Training Random Forest Regressor ---\n",
      "\n",
      "--- Model Evaluation ---\n",
      "Mean Absolute Error: 1.3656\n",
      "Mean Squared Error: 11.2414\n",
      "RÂ² Score: 0.8318\n"
     ]
    }
   ],
   "source": [
    "# train_model.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Load Dataset ---\n",
    "print(\"--- Loading dataset ---\")\n",
    "df = pd.read_csv('master_dataset_cleaned.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# --- 2. Feature / Target Split ---\n",
    "X = df.drop(\"Total\", axis=1)\n",
    "y = df[\"Total\"]\n",
    "\n",
    "# --- 3. Train-Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- 4. Model Training ---\n",
    "print(\"--- Training Random Forest Regressor ---\")\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    n_jobs=-1, \n",
    "    min_samples_leaf=5\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- 5. Evaluate Model ---\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred[y_pred < 0] = 0\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "# # --- 6. Save Model ---\n",
    "# model_filename = \"random_forest_model.pkl\"\n",
    "# joblib.dump(model, model_filename)\n",
    "# print(f\"\\nâœ… Model saved as '{model_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading dataset ---\n",
      "Dataset shape: (20032, 7)\n",
      "--- Training Random Forest Regressor ---\n",
      "\n",
      "--- Model Evaluation ---\n",
      "Mean Absolute Error: 1.3656\n",
      "Mean Squared Error: 11.2414\n",
      "RÂ² Score: 0.8318\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Load Dataset ---\n",
    "print(\"--- Loading dataset ---\")\n",
    "df = pd.read_csv('master_dataset_cleaned.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# --- ðŸ”¹ Custom Aggregation ---\n",
    "# Sum 'Total' for rows matching Year=2023, Case=1, Consultation_Type=3\n",
    "filtered_sum = df.loc[\n",
    "    (df[\"Year\"] == 2023) &\n",
    "    (df[\"Case\"] == 1) &\n",
    "    (df[\"Consultation_Type\"] == 3),\n",
    "    \"Total\"\n",
    "].sum()\n",
    "\n",
    "print(f\"\\nðŸ”¸ Total cases for Year=2023, Case=1, Consultation_Type=3: {filtered_sum}\")\n",
    "\n",
    "# --- 2. Feature / Target Split ---\n",
    "X = df.drop(\"Total\", axis=1)\n",
    "y = df[\"Total\"]\n",
    "\n",
    "# --- 3. Train-Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- 4. Model Training ---\n",
    "print(\"\\n--- Training Random Forest Regressor ---\")\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    n_jobs=-1, \n",
    "    min_samples_leaf=5\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- 5. Evaluate Model ---\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred[y_pred < 0] = 0\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "# --- 6. Save Model ---\n",
    "# model_filename = \"random_forest_model.pkl\"\n",
    "# joblib.dump(model, model_filename)\n",
    "# print(f\"\\nâœ… Model saved as '{model_filename}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
